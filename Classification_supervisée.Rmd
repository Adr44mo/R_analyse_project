---
title: "Classification suppervisée"
author: ""
date: "2025-04-03"
output: html_document
---

## Classification suppervisée

```{r,warning=FALSE,echo=FALSE,message=FALSE,results='hide'}
set.seed(1)
data=cleaned_data
donnee <- data[!is.na(data$forwardPE),]
donnee$forwardPE <- as.numeric(as.character(donnee$forwardPE))
sum(is.na(donnee$forwardPE))

donnee$forwardPE_class <- cut(donnee$forwardPE, 
                                    breaks = quantile(donnee$forwardPE, probs = c(0, 0.33, 0.66, 1), na.rm = TRUE),
                                    labels = c("Bas", "Moyen", "Élevé"),
                                    include.lowest = TRUE)
#remove the column forwardPE
donnee <- donnee[,-which(names(donnee) %in% c("forwardPE"))]
table(donnee$forwardPE_class)

```

```{r,warning=FALSE,echo=FALSE,message=FALSE,results='hide'}

# Calculer la taille du jeu de test (20%)
test_size <- 0.2

# Créer des indices aléatoires pour diviser les données
indices <- sample(1:nrow(donnee))
# Sélectionner les indices pour le jeu de test (20% des données)
test_indices <- indices[1:floor(test_size * nrow(donnee))]

# Sélectionner les données de test et d'entraînement
data_test <- donnee[test_indices, ]  # Données de test (20%)
data_train <- donnee[-test_indices, ]  # Données d'entraînement (80%)
table(data_test$forwardPE_class)
table(data_train$forwardPE_class)

# Supprimer les lignes contenant des valeurs manquantes
data_train_clean <- na.omit(data_train)
data_test_clean <- na.omit(data_test)

table(data_test_clean$forwardPE_class)
table(data_train_clean$forwardPE_class)

```

### Prédiction de la variable forwardPE avec Random Forest

La variable forwardPE (Forward Price-to-Earnings) est un ratio financier qui mesure le rapport entre le prix actuel de l'action et les bénéfices futurs estimés d'une entreprise.C'est donc une variable interssante à prédire. Pour se faire, nous avons converti forwardPE en forwardPE_class prenant des valeurs qualitatives ("élevé"(33%),"moyen"(33%),bas"(33%)) et nous avons découpé les données aléatoirement en données d'entrainement (80%) et données de test (20%) et nous allons effectuer une Random Forest qui s'applique bien dans notre cas car pour prédire forwardPE_class avec nos données mixtes (qualitatives et quantitatives). De part la construction de forwardPE_class nous avons aussi la certitude que nos données sont bien réparties dans les classes.

```{r,warning=FALSE,echo=FALSE,message=FALSE,results='hide'}
library(randomForest)

rf_model <- randomForest(forwardPE_class ~ ., data = data_train_clean)


# Afficher l'importance des variables
importance <- importance(rf_model)
importance_df <- data.frame(Variable = rownames(importance), Importance = importance[, 1])

# Trier par importance décroissante
importance_df <- importance_df %>% arrange(desc(Importance))

# Afficher les 10 variables les plus importantes
print(importance_df[1:10, ])

plot(rf_model)

```

On remarque que les erreurs sont constantes pour toutes les classes à partir d'environ 100 arbres dans notre random forest. On choisit de prendre le nombre d'abres égal à 100.

Analyse du graphe et de l'importances

```{r,warning=FALSE,echo=FALSE,message=FALSE}
rf_model <- randomForest(forwardPE_class ~ ., data = data_train_clean, ntree = 100)
pred=predict(rf_model,newdata=data_test_clean)
table(pred,data_test_clean$forwardPE_class)
library(pROC)
pred_RF = predict(rf_model, data_test_clean, type="prob")[,2]
ROC_RF <- roc(data_test_clean$forwardPE_class, pred_RF)
ROC_RF$auc 
accuracy_RF = mean(pred == data_test_clean$forwardPE_class)
print(paste("accuracy =", accuracy_RF))
```

Nous remarquons pour le choix de 100 arbres, une matrice de confusion avec des erreurs répartie de manière homogène entre les classes. Nous avons aussi une précisions de 76% cela veut dire que 76% de nos individus sont classés dans la bonne classe. Nous avons une aire sous la courbe ROC de 0,87 se qui signifie que le taux de "vrais positifs" est de 87% et le taux de "faux positifs" est de 20%. Cela signifie que notre modèle est assez bon pour prédire la classe de forwardPE_class.


### Prédiction de la variable forwardPE avec CART (Classification and Regression Trees)

Nous avons essayer d'utiliser une autre méthode pour la prédiction de forwardPE_class, la méthode CART. Cependant, l'éxécution du code n'arrivait jamais à bout, nous avons donc abandonner cette méthode mais nous avons mis le code en annexe.

```{r,warning=FALSE,echo=FALSE,message=FALSE,results='hide'}
#library(rpart)
#library(rpart.plot)
#set.seed(1)
#arbre=rpart(forwardPE_class~.,data_train_clean,control=rpart.control(minsplit=5,cp=0))
#printcp(arbre)

#plotcp(arbre)
```

### Prédiction de la variable priceToBook

Nous allons maintenant prédire la variable priceToBook qui est un ratio financier qui mesure le rapport de son prix de marché (valeur de marché) sur la valeur comptable d'une entreprise (valeur réelle). C'est un indicateur important permettant de déceler si une entreprise et sous ou sur évaluée, en particulier, un priceToBook inférieur à 1 indique que l'entreprise est sous-évaluée. Nous allons donc essayer de prédire si une entreprise est sous-évaluée (priceToBook=0) ou surévaluée (priceToBook=1). De ce fait, nous modifions la variable priceToBook de façon à ce que si le ratio est strictement inférieur à 1 alors nous mettons la valeur à zéro et si elle est supérieur à 1 nous mettons 1. Ensuite, nous convertissons cette ligne en facteurs. Nous allons éffectuer un maximum de méthodes de prédictions et nous finirons par leur comparaisons afin de déterminer laquelle est la mieux adaptée.

```{r,warning=FALSE,echo=FALSE}
# préparation des données

data_priceToBook <- data[!is.na(data$priceToBook),]

data_priceToBook$priceToBook  = ifelse(data_priceToBook$priceToBook < 1, 0, 1)

print('table de priceToBook')
table(data_priceToBook$priceToBook)

data_priceToBook$priceToBook <- as.numeric(as.character(data_priceToBook$priceToBook))

#On garde que les data quantitatives
data_priceToBook <- data_priceToBook[,sapply(data_priceToBook, is.numeric)]

data_priceToBook$priceToBook <- as.factor(data_priceToBook$priceToBook)
#----------------------------------------
  # Calculer la taille du jeu de test (20%)
test_size <- 0.2

# Créer des indices aléatoires pour diviser les données
indices <- sample(1:nrow(data_priceToBook))
# Sélectionner les indices pour le jeu de test (20% des données)
test_indices <- indices[1:floor(test_size * nrow(data_priceToBook))]

# Sélectionner les données de test et d'entraînement
data_test <- data_priceToBook[test_indices, ]  # Données de test (20%)
data_train <- data_priceToBook[-test_indices, ]  # Données d'entraînement (80%)

#---------------------------------------------

data_train_priceToBook = data_train
data_test_priceToBook = data_test

data_train_priceToBook <- na.omit(data_train_priceToBook)
data_test_priceToBook <- na.omit(data_test_priceToBook)

data_train_priceToBook_smote = SMOTE(priceToBook ~ ., data_train_priceToBook)

# adaboost
# on pase toutes les variables qualitatives en quantitatif (sauf priceToBook)

data_train_adaboost <- data_train_priceToBook_smote

data_test_adaboost <- data_test_priceToBook


print('table de nos données d\'entrainement après rééchantillonages')
table(data_train_adaboost$priceToBook)

```

Nous remarquons que nos données initiales ne sont pas bien réparties, beaucoup d'individus sont dans la classe 1 et peu dans la classe 0, nous avons donc utilisée une méthode de rééchantillonage SMOTE afin de rééquilibrer le jeu de données d'entraineemnt.

### Prédiction de la variable priceToBook avec Adaboost

Nous allons maintenant prédire la variable priceToBook avec la méthode Adaboost. Nous avons conservé uniquement les données quantitatives.

```{r,warning=FALSE,echo=FALSE}
set.seed(1)
# Entraîner le modèle Adaboost
adaboost_model <- gbm(as.numeric(priceToBook)-1 ~ ., data = data_train_adaboost,distribution = "adaboost")
adaboost_model
adaboost_model=gbm(as.numeric(priceToBook)-1 ~., data_train_adaboost, distribution = "adaboost",cv.folds = 5,shrinkage = 0.01, n.trees = 1000)
B.opt = gbm.perf(adaboost_model, method="cv")

```

En affichant l'erreur de validation croisée, nous obtenons un nombre d'arbres optimal que nous pouvons maintenant utiliser pour la prédiction 

```{r,warning=FALSE,echo=FALSE,message=FALSE}

pred_adaboost = predict(adaboost_model, newdata=data_test_adaboost, type = "response", n.trees = B.opt)
class_adaboost <- 1*(pred_adaboost >1/2)
table(class_adaboost, data_test_adaboost$priceToBook)
accuracy_adaboost = mean(class_adaboost == data_test_adaboost$priceToBook)
print(paste("accuracy =", accuracy_adaboost))
ROC_adaboost <- roc(data_test_adaboost$priceToBook, pred_adaboost)
ROC_adaboost$auc
```
Nous remarquons que la matrice de confusion est bien répartie entre les classes et que nous avons une précision de 88% ainsi qu'une très bonne aire sous la courbe ROC de 0,93 ce qui semble être de bons résultats.

### Prédiction de la variable priceToBook avec Lasso

Nous allons mainteant effectuer une régression logistique avec Lasso.
```{r,echo=FALSE,warning=FALSE,message=FALSE}
# Extraire X (features) et y (cible)

X_train <- as.matrix(data_train_priceToBook_smote[, -5])  # Supprime la 5ème colonne (priceToBook)
y_train <- as.factor(data_train_priceToBook_smote[, 5])   # Sélectionne la 5ème colonne

X_test=as.matrix(data_test_priceToBook[, -5])  # Supprime la 5ème colonne (priceToBook)
Y_test=as.factor(data_test_priceToBook[, 5])   # Sélectionne la 5ème colonne

# Entraîner le modèle Lasso (régression logistique pénalisée)
res_lasso <- glmnet(X_train, y_train, family = 'binomial', alpha = 1)

# Afficher la trajectoire des coefficients en fonction de lambda
plot(res_lasso, label = TRUE)
plot(res_lasso, xvar = "lambda", label = TRUE) # en abscisse : log(lambda)

```

Nous allons choisir lambda par cross validation 

```{r,echo=FALSE,warning=FALSE,message=FALSE,results='hide'}
cvlasso=cv.glmnet(X_train, y_train, family = "binomial",type.measure="class")
plot(cvlasso)
cvlasso$lambda.min
```

Nous allons maintenant choisir le lambda optimal et faire la prédiction sur le jeu de test.

```{r,warning=FALSE,message=FALSE,echo=FALSE}

class_logit_lasso=predict(cvlasso, newx = X_test, s = 'lambda.min', type = "class")
table(class_logit_lasso,Y_test)
accuracy_logit_lasso = mean(class_logit_lasso == Y_test)
accuracy_logit_lasso
pred_logit_lasso = predict(cvlasso, newx = X_test, s = 'lambda.min', type = "response")
ROC_logit_lasso <- roc(Y_test, pred_logit_lasso)
ROC_logit_lasso$auc
```
Nous avons une matrice de confusion bien répartie entre les classes et une précision de 88% ainsi qu'une aire sous la courbe ROC de 0,83 ce qui est relativement bon


### Prédiction de la variable priceToBook avec LDA et QDA

Nous allons mainteant faire une LDA et une QDA. A priori, nous n'avons pas d'information sur l'homoscédasticité de nos données, nous allons donc faire les deux méthodes et les comparer pour voir à posteriori si cela est pertinent.

```{r,warning=FALSE,message=FALSE,echo=FALSE}
# Entraîner LDA et QDA
res_lda <- lda(priceToBook ~ ., data_train_priceToBook_smote)
res_qda <- qda(priceToBook ~ ., data_train_priceToBook_smote)

# Prédictions sous forme de probabilités
pred_lda_prob <- predict(res_lda, newdata = data_test_priceToBook)$posterior[,2]
pred_qda_prob <- predict(res_qda, newdata = data_test_priceToBook)$posterior[,2]

# Convertir les probabilités en classes (seuil = 0.5)
pred_lda_class <- ifelse(pred_lda_prob > 0.5, 1, 0)
pred_qda_class <- ifelse(pred_qda_prob > 0.5, 1, 0)

# Matrice de confusion
table(pred_lda_class, data_test_priceToBook$priceToBook)
table(pred_qda_class, data_test_priceToBook$priceToBook)

# Calculer l'accuracy
accuracy_lda <- mean(pred_lda_class == data_test_priceToBook$priceToBook)
accuracy_qda <- mean(pred_qda_class == data_test_priceToBook$priceToBook)

# Affichage des accuracies
print(accuracy_lda)
print(accuracy_qda)

# Calcul de l'AUC
ROC_lda <- roc(data_test_priceToBook$priceToBook, pred_lda_prob)
ROC_qda <- roc(data_test_priceToBook$priceToBook, pred_qda_prob)

# Affichage de l'AUC
print(ROC_lda$auc)
print(ROC_qda$auc)

```

Nous remarquons des résultats étonnant, malgré des précisions proches, l'air sous la courbe ROC de la QDA n'est que de 0,52 contre 0,85 pour celle de la lda.


### Prédiction de la variable priceToBook avec Random Forest

Nous allons maintenant effectuer une Random Forest
```{r,warning=FALSE,message=FALSE,echo=FALSE}
set.seed(1)
library(randomForest)
rf_model_priceToBook <- randomForest(priceToBook ~ ., data = data_train_priceToBook_smote, ntree = 100)
pred_rf_priceToBook <- predict(rf_model_priceToBook, newdata = data_test_priceToBook)
table(pred_rf_priceToBook, data_test_priceToBook$priceToBook)
accuracy_rf_priceToBook <- mean(pred_rf_priceToBook == data_test_priceToBook$priceToBook)
accuracy_rf_priceToBook
pred_rf_priceToBook_prob <- predict(rf_model_priceToBook, newdata = data_test_priceToBook, type = "prob")[,2]
ROC_rf_priceToBook <- roc(data_test_priceToBook$priceToBook, pred_rf_priceToBook_prob)
ROC_rf_priceToBook$auc
```
Nous avons une matrice de confusion bien répartie entre les classes et une précision de 95% ainsi qu'une aire sous la courbe ROC de 0,95. Ce sont des excellent résultats.


### Comparaison des modèles et conclusion
Enfin, nous allons comparer tout nos modèles et conclure.

```{r,warning=FALSE,message=FALSE,echo=FALSE}
result=matrix(NA, ncol=5, nrow=2)
rownames(result)=c('accuracy', 'AUC')
colnames(result)=c('lda', 'qda', 'RF', "adaboost", 'logit_lasso')
result[1,]= c(accuracy_lda, accuracy_qda, accuracy_rf_priceToBook,accuracy_adaboost, accuracy_logit_lasso)
result[2,]=c(ROC_lda$auc, ROC_qda$auc, ROC_rf_priceToBook$auc, ROC_adaboost$auc, ROC_logit_lasso$auc)

result


#apply(result,1, which.max )

```

```{r,warning=FALSE,message=FALSE,echo=FALSE}
plot(ROC_lda, xlim=c(1,0),print.auc=TRUE,print.auc.y=0.5, col=1, lwd=2, main="Courbes ROC")
plot(ROC_qda, add=TRUE, col=2,print.auc=TRUE,print.auc.y=0.4, lwd=2, main="Courbes ROC")
plot(ROC_rf_priceToBook, add=TRUE, col=3,print.auc=TRUE,print.auc.y=0.3, lwd=2, main="Courbes ROC")
plot(ROC_adaboost, add=TRUE, col=4,print.auc=TRUE,print.auc.y=0.2, lwd=2, main="Courbes ROC")
plot(ROC_logit_lasso, add=TRUE, col=5,print.auc=TRUE,print.auc.y=0.1, lwd=2, main="Courbes ROC")
legend('bottomright', col=1:5, paste(c('lda', 'qda', 'RF', "ada", 'logit_lasso')), lwd=1)
```
Nous observons ainsi que la méthode de Random forest est la meilleure que cela soit en terme d'aire sous la bourbe ROC ou de précisions. Cependant, il faudrait faire plus de test pour chacune des méthode et faire une moyenne pour obtenir veritablement une conclusion définitive. 