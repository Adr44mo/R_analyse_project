---
title: "Classification suppervisée"
author: ""
date: "2025-04-03"
output: html_document
---
## Classification suppervisée

```{r}
data=cleaned_data
donnee <- data[!is.na(data$forwardPE),]
donnee$forwardPE <- as.numeric(as.character(donnee$forwardPE))
sum(is.na(donnee$forwardPE))

donnee$forwardPE_class <- cut(donnee$forwardPE, 
                                    breaks = quantile(donnee$forwardPE, probs = c(0, 0.33, 0.66, 1), na.rm = TRUE),
                                    labels = c("Bas", "Moyen", "Élevé"),
                                    include.lowest = TRUE)
#remove the column forwardPE
donnee <- donnee[,-which(names(donnee) %in% c("forwardPE"))]
table(donnee$forwardPE_class)

```

```{r}

# Calculer la taille du jeu de test (20%)
test_size <- 0.2

# Créer des indices aléatoires pour diviser les données
indices <- sample(1:nrow(donnee))
# Sélectionner les indices pour le jeu de test (20% des données)
test_indices <- indices[1:floor(test_size * nrow(donnee))]

# Sélectionner les données de test et d'entraînement
data_test <- donnee[test_indices, ]  # Données de test (20%)
data_train <- donnee[-test_indices, ]  # Données d'entraînement (80%)
table(data_test$forwardPE_class)
table(data_train$forwardPE_class)

# Supprimer les lignes contenant des valeurs manquantes
data_train_clean <- na.omit(data_train)
data_test_clean <- na.omit(data_test)

table(data_test_clean$forwardPE_class)
table(data_train_clean$forwardPE_class)

```

### Prédiction de la variable forwardPE avec Random Forest
```{r}
library(randomForest)

rf_model <- randomForest(forwardPE_class ~ ., data = data_train_clean)


# Afficher l'importance des variables
importance <- importance(rf_model)
importance_df <- data.frame(Variable = rownames(importance), Importance = importance[, 1])

# Trier par importance décroissante
importance_df <- importance_df %>% arrange(desc(Importance))

# Afficher les 10 variables les plus importantes
print(importance_df[1:10, ])

plot(rf_model)

```
Analyse du graphe et de l'importances 


```{r}
rf_model <- randomForest(forwardPE_class ~ ., data = data_train_clean, ntree = 100)
pred=predict(rf_model,newdata=data_test_clean)
table(pred,data_test_clean$forwardPE_class)
```

```{r}
accuracy_RF = mean(pred == data_test_clean$forwardPE_class)
accuracy_RF
```

```{r}
library(pROC)
pred_RF = predict(rf_model, data_test_clean, type="prob")[,2]
ROC_RF <- roc(data_test_clean$forwardPE_class, pred_RF)
ROC_RF$auc 
```
table de confusion + accuracy
 + courbe ROC 

### Prédiction de la variable forwardPE avec CART (Classification and Regression Trees)

trop long
```{r}
#library(rpart)
#library(rpart.plot)
#set.seed(1)
#arbre=rpart(forwardPE_class~.,data_train_clean,control=rpart.control(minsplit=5,cp=0))
#printcp(arbre)

#plotcp(arbre)
```


## Prédiction de la variable priceToBook

```{r}

library(gbm)
# préparation des données

data_priceToBook <- data[!is.na(data$priceToBook),]

data_priceToBook$priceToBook  = ifelse(data_priceToBook$priceToBook < 1, 0, 1)

data_priceToBook$priceToBook <- as.numeric(as.character(data_priceToBook$priceToBook))

#On garde que les data quantitatives
data_priceToBook <- data_priceToBook[,sapply(data_priceToBook, is.numeric)]

sum(is.na(data_priceToBook$priceToBook))
data_priceToBook$priceToBook <- as.factor(data_priceToBook$priceToBook)
#----------------------------------------
  # Calculer la taille du jeu de test (20%)
test_size <- 0.2

# Créer des indices aléatoires pour diviser les données
indices <- sample(1:nrow(data_priceToBook))
# Sélectionner les indices pour le jeu de test (20% des données)
test_indices <- indices[1:floor(test_size * nrow(data_priceToBook))]

# Sélectionner les données de test et d'entraînement
data_test <- data_priceToBook[test_indices, ]  # Données de test (20%)
data_train <- data_priceToBook[-test_indices, ]  # Données d'entraînement (80%)

#---------------------------------------------

data_train_priceToBook = data_train
data_test_priceToBook = data_test

data_train_priceToBook <- na.omit(data_train_priceToBook)
data_test_priceToBook <- na.omit(data_test_priceToBook)

data_train_priceToBook_smote = SMOTE(priceToBook ~ ., data_train_priceToBook)

# adaboost
# on pase toutes les variables qualitatives en quantitatif (sauf priceToBook)

data_train_adaboost <- data_train_priceToBook_smote

data_test_adaboost <- data_test_priceToBook



table(data_train_adaboost$priceToBook)
table(data_test_adaboost$priceToBook)

```


## Prédiction de la variable priceToBook avec Adaboost


```{r}
library(DMwR)
library(gbm)

# Entraîner le modèle Adaboost
adaboost_model <- gbm(as.numeric(priceToBook)-1 ~ ., data = data_train_adaboost,distribution = "adaboost")
adaboost_model
adaboost_model=gbm(as.numeric(priceToBook)-1 ~., data_train_adaboost, distribution = "adaboost",cv.folds = 5,shrinkage = 0.01, n.trees = 1000)
B.opt = gbm.perf(adaboost_model, method="cv")

```

```{r}
library(pROC)
pred_adaboost = predict(adaboost_model, newdata=data_test_adaboost, type = "response", n.trees = B.opt)
class_adaboost <- 1*(pred_adaboost >1/2)
table(class_adaboost, data_test_adaboost$priceToBook)
accuracy_adaboost = mean(class_adaboost == data_test_adaboost$priceToBook)
accuracy_adaboost
ROC_adaboost <- roc(data_test_adaboost$priceToBook, pred_adaboost)
ROC_adaboost$auc
```

```{r}
library(glmnet)

# Extraire X (features) et y (cible)

X_train <- as.matrix(data_train_priceToBook_smote[, -5])  # Supprime la 5ème colonne (priceToBook)
y_train <- as.factor(data_train_priceToBook_smote[, 5])   # Sélectionne la 5ème colonne

X_test=as.matrix(data_test_priceToBook[, -5])  # Supprime la 5ème colonne (priceToBook)
Y_test=as.factor(data_test_priceToBook[, 5])   # Sélectionne la 5ème colonne

# Entraîner le modèle Lasso (régression logistique pénalisée)
res_lasso <- glmnet(X_train, y_train, family = 'binomial', alpha = 1)

# Afficher la trajectoire des coefficients en fonction de lambda
plot(res_lasso, label = TRUE)
plot(res_lasso, xvar = "lambda", label = TRUE) # en abscisse : log(lambda)

```

Choix de lambda par cross validation

```{r}
cvlasso=cv.glmnet(X_train, y_train, family = "binomial",type.measure="class")
plot(cvlasso)
cvlasso$lambda.min
```

Prediction

```{r,warning=FALSE}

class_logit_lasso=predict(cvlasso, newx = X_test, s = 'lambda.min', type = "class")
table(class_logit_lasso,Y_test)
accuracy_logit_lasso = mean(class_logit_lasso == Y_test)
accuracy_logit_lasso
```

Courbe ROC

```{r}
pred_logit_lasso = predict(cvlasso, newx = X_test, s = 'lambda.min', type = "response")
ROC_logit_lasso <- roc(Y_test, pred_logit_lasso)
ROC_logit_lasso$auc
```

LDA/QDA

```{r}
# Charger les bibliothèques
library(MASS)
library(pROC)

# Entraîner LDA et QDA
res_lda <- lda(priceToBook ~ ., data_train_priceToBook_smote)
res_qda <- qda(priceToBook ~ ., data_train_priceToBook_smote)

# Prédictions sous forme de probabilités
pred_lda_prob <- predict(res_lda, newdata = data_test_priceToBook)$posterior[,2]
pred_qda_prob <- predict(res_qda, newdata = data_test_priceToBook)$posterior[,2]

# Convertir les probabilités en classes (seuil = 0.5)
pred_lda_class <- ifelse(pred_lda_prob > 0.5, 1, 0)
pred_qda_class <- ifelse(pred_qda_prob > 0.5, 1, 0)

# Matrice de confusion
table(pred_lda_class, data_test_priceToBook$priceToBook)
table(pred_qda_class, data_test_priceToBook$priceToBook)

# Calculer l'accuracy
accuracy_lda <- mean(pred_lda_class == data_test_priceToBook$priceToBook)
accuracy_qda <- mean(pred_qda_class == data_test_priceToBook$priceToBook)

# Affichage des accuracies
print(accuracy_lda)
print(accuracy_qda)

# Calcul de l'AUC
ROC_lda <- roc(data_test_priceToBook$priceToBook, pred_lda_prob)
ROC_qda <- roc(data_test_priceToBook$priceToBook, pred_qda_prob)

# Affichage de l'AUC
print(ROC_lda$auc)
print(ROC_qda$auc)

```
Random Forest
```{r}
library(randomForest)
rf_model_priceToBook <- randomForest(priceToBook ~ ., data = data_train_priceToBook_smote, ntree = 100)
pred_rf_priceToBook <- predict(rf_model_priceToBook, newdata = data_test_priceToBook)
table(pred_rf_priceToBook, data_test_priceToBook$priceToBook)
accuracy_rf_priceToBook <- mean(pred_rf_priceToBook == data_test_priceToBook$priceToBook)
accuracy_rf_priceToBook
pred_rf_priceToBook_prob <- predict(rf_model_priceToBook, newdata = data_test_priceToBook, type = "prob")[,2]
ROC_rf_priceToBook <- roc(data_test_priceToBook$priceToBook, pred_rf_priceToBook_prob)
ROC_rf_priceToBook$auc
```
Comparaison des modèles

```{r}
result=matrix(NA, ncol=5, nrow=2)
rownames(result)=c('accuracy', 'AUC')
colnames(result)=c('lda', 'qda', 'RF', "adaboost", 'logit_lasso')
result[1,]= c(accuracy_lda, accuracy_qda, accuracy_rf_priceToBook,accuracy_adaboost, accuracy_logit_lasso)
result[2,]=c(ROC_lda$auc, ROC_qda$auc, ROC_RF$auc, ROC_adaboost$auc, ROC_logit_lasso$auc)

result


#apply(result,1, which.max )

```

```{r}
plot(ROC_lda, xlim=c(1,0),print.auc=TRUE,print.auc.y=0.5, col=1, lwd=2, main="Courbes ROC")
plot(ROC_qda, add=TRUE, col=2,print.auc=TRUE,print.auc.y=0.4, lwd=2, main="Courbes ROC")
plot(ROC_RF, add=TRUE, col=3,print.auc=TRUE,print.auc.y=0.3, lwd=2, main="Courbes ROC")
plot(ROC_adaboost, add=TRUE, col=4,print.auc=TRUE,print.auc.y=0.2, lwd=2, main="Courbes ROC")
plot(ROC_logit_lasso, add=TRUE, col=5,print.auc=TRUE,print.auc.y=0.1, lwd=2, main="Courbes ROC")
legend('bottomright', col=1:5, paste(c('lda', 'qda', 'RF', "ada", 'logit_lasso')), lwd=1)
```

